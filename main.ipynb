{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pygame as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningConfig:\n",
    "    def __init__(self, env_name):\n",
    "        # Define the parameter table\n",
    "        self.configs = {\n",
    "            \"FrozenLake-v1 (4x4)\": {\n",
    "                \"n_train_episodes\": 10000,\n",
    "                \"lr\": 0.7,\n",
    "                \"n_eval_episodes\": 100,\n",
    "                \"max_steps\": 100,\n",
    "                \"gamma\": 0.95,\n",
    "                \"min_epsilon\": 0.05,\n",
    "                \"max_epsilon\": 1.0,\n",
    "                \"decay\": 0.0005\n",
    "            },\n",
    "            \"FrozenLake-v1 (4x4 - slippery)\": {\n",
    "                \"n_train_episodes\": 10000,\n",
    "                \"lr\": 0.1,\n",
    "                \"n_eval_episodes\": 100,\n",
    "                \"max_steps\": 100,\n",
    "                \"gamma\": 0.99,\n",
    "                \"min_epsilon\": 0.05,\n",
    "                \"max_epsilon\": 1.0,\n",
    "                \"decay\": 0.0005\n",
    "            },\n",
    "            \"FrozenLake-v1 (8x8)\": {\n",
    "                \"n_train_episodes\": 250000,\n",
    "                \"lr\": 0.8,\n",
    "                \"n_eval_episodes\": 1000,\n",
    "                \"max_steps\": 400,\n",
    "                \"gamma\": 0.9,\n",
    "                \"min_epsilon\": 0.001,\n",
    "                \"max_epsilon\": 1.0,\n",
    "                \"decay\": 0.00005\n",
    "            },\n",
    "            \"FrozenLake-v1 (8x8, slippery)\": {\n",
    "                \"n_train_episodes\": 250000,\n",
    "                \"lr\": 0.1,\n",
    "                \"n_eval_episodes\": 1000,\n",
    "                \"max_steps\": 400,\n",
    "                \"gamma\": 0.99,\n",
    "                \"min_epsilon\": 0.05,\n",
    "                \"max_epsilon\": 1.0,\n",
    "                \"decay\": 0.00005\n",
    "            },\n",
    "            \"Taxi-v3\": {\n",
    "                \"n_train_episodes\": 10000,\n",
    "                \"lr\": 0.7,\n",
    "                \"n_eval_episodes\": 100,\n",
    "                \"max_steps\": 100,\n",
    "                \"gamma\": 0.95,\n",
    "                \"min_epsilon\": 0.05,\n",
    "                \"max_epsilon\": 1.0,\n",
    "                \"decay\": 0.0005\n",
    "            },\n",
    "            \"CliffWalking-v0\": {\n",
    "                \"n_train_episodes\": 10000,\n",
    "                \"lr\": 0.7,\n",
    "                \"n_eval_episodes\": 100,\n",
    "                \"max_steps\": 100,\n",
    "                \"gamma\": 0.95,\n",
    "                \"min_epsilon\": 0.05,\n",
    "                \"max_epsilon\": 1.0,\n",
    "                \"decay\": 0.0005\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Load the configuration for the selected environment\n",
    "        if env_name in self.configs:\n",
    "            self.params = self.configs[env_name]\n",
    "        else:\n",
    "            raise ValueError(f\"Environment '{env_name}' not found in configurations.\")\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef list_all_envs():\\n    # Get all registered environments\\n    all_envs = gym.envs.registry.values()\\n\\n    # Extract and print environment IDs\\n    env_ids = sorted(set(env_spec.id for env_spec in all_envs))\\n    print(\"Available Gymnasium Environments:\")\\n    for env_id in env_ids:\\n        print(env_id)\\n\\n# Call the function\\nlist_all_envs()\\'\\n'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def list_all_envs():\n",
    "    # Get all registered environments\n",
    "    all_envs = gym.envs.registry.values()\n",
    "    \n",
    "    # Extract and print environment IDs\n",
    "    env_ids = sorted(set(env_spec.id for env_spec in all_envs))\n",
    "    print(\"Available Gymnasium Environments:\")\n",
    "    for env_id in env_ids:\n",
    "        print(env_id)\n",
    "\n",
    "# Call the function\n",
    "list_all_envs()'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of said parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Environment: CliffWalking-v0\n",
      "Parameters: {'n_train_episodes': 10000, 'lr': 0.7, 'n_eval_episodes': 100, 'max_steps': 100, 'gamma': 0.95, 'min_epsilon': 0.05, 'max_epsilon': 1.0, 'decay': 0.0005}\n",
      "Slippery: N/A\n"
     ]
    }
   ],
   "source": [
    "env_param_pairs = [\n",
    "    (\"FrozenLake-v1\", \"FrozenLake-v1 (4x4)\"),                   # 0\n",
    "    (\"FrozenLake-v1\", \"FrozenLake-v1 (4x4 - slippery)\"),        # 1\n",
    "    (\"FrozenLake8x8-v1\", \"FrozenLake-v1 (8x8)\"),                # 2\n",
    "    (\"FrozenLake8x8-v1\", \"FrozenLake-v1 (8x8, slippery)\"),      # 3\n",
    "    (\"Taxi-v3\", \"Taxi-v3\"),                                     # 4\n",
    "    (\"CliffWalking-v0\", \"CliffWalking-v0\")                      # 5\n",
    "]\n",
    "\n",
    "################################\n",
    "# Select the environment index #\n",
    "################################\n",
    "index = 5\n",
    "env_name, env_name_long = env_param_pairs[index]\n",
    "\n",
    "if \"FrozenLake\" in env_name:\n",
    "    env = gym.make(env_name, render_mode=\"rgb_array\", is_slippery=(\"slippery\" in env_name_long))\n",
    "else:\n",
    "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
    "\n",
    "config = QLearningConfig(env_name_long)\n",
    "\n",
    "params = config.get_params()\n",
    "\n",
    "n_train_episodes = params[\"n_train_episodes\"]\n",
    "lr = params[\"lr\"]\n",
    "n_eval_episodes = params[\"n_eval_episodes\"]\n",
    "max_steps = params[\"max_steps\"]\n",
    "gamma = params[\"gamma\"]\n",
    "min_epsilon = params[\"min_epsilon\"]\n",
    "max_epsilon = params[\"max_epsilon\"]\n",
    "decay = params[\"decay\"]\n",
    "\n",
    "print(f\"Selected Environment: {env_name_long}\")\n",
    "print(f\"Parameters: {params}\")\n",
    "print(f\"Slippery: {'slippery' in env_name_long if 'FrozenLake' in env_name else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traing agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "done = False\n",
    "frames = []\n",
    "Q_table = np.zeros((num_states, num_actions))\n",
    "\n",
    "for ep in range(n_train_episodes):\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * ep)\n",
    "    obs, _ = env.reset()\n",
    "    for _ in range(max_steps):\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = int(np.argmax(Q_table[obs]))\n",
    "        new_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        Q_table[obs, action] += lr * (reward + gamma * (not truncated and not terminated) * np.max(Q_table[new_obs]) - Q_table[obs, action])\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        obs = new_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = np.argmax(Q_table[obs])\n",
    "    new_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    frames.append(env.render())\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "    obs = new_obs\n",
    "\n",
    "env.close()\n",
    "\n",
    "imageio.mimsave('results/' + env_name_long + '.gif', frames, fps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
